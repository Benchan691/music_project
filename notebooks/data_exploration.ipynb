{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Instrument and Note Classifier - Data Exploration\n",
        "\n",
        "This notebook helps explore and visualize the audio data used for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import pandas as pd\n",
        "from IPython.display import Audio\n",
        "\n",
        "import config\n",
        "from audio_processor import AudioProcessor\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count samples per instrument and split\n",
        "def count_samples(data_dir):\n",
        "    counts = {}\n",
        "    for instrument in config.INSTRUMENTS:\n",
        "        instrument_dir = os.path.join(data_dir, instrument)\n",
        "        if os.path.exists(instrument_dir):\n",
        "            files = [f for f in os.listdir(instrument_dir) \n",
        "                    if f.lower().endswith(('.wav', '.mp3', '.ogg', '.flac'))]\n",
        "            counts[instrument] = len(files)\n",
        "        else:\n",
        "            counts[instrument] = 0\n",
        "    return counts\n",
        "\n",
        "# Count for each split\n",
        "train_counts = count_samples(config.TRAIN_DIR)\n",
        "val_counts = count_samples(config.VAL_DIR)\n",
        "test_counts = count_samples(config.TEST_DIR)\n",
        "\n",
        "# Create DataFrame\n",
        "df_counts = pd.DataFrame({\n",
        "    'Train': train_counts,\n",
        "    'Validation': val_counts,\n",
        "    'Test': test_counts\n",
        "})\n",
        "\n",
        "print(\"Dataset Statistics:\")\n",
        "print(df_counts)\n",
        "print(f\"\\nTotal samples: {df_counts.sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize distribution\n",
        "df_counts.plot(kind='bar', figsize=(12, 6))\n",
        "plt.title('Sample Distribution by Instrument and Split')\n",
        "plt.xlabel('Instrument')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.legend(title='Split')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Audio Waveform Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and visualize sample audio files\n",
        "processor = AudioProcessor()\n",
        "\n",
        "def visualize_audio(audio_path):\n",
        "    \"\"\"Visualize audio waveform and spectrogram\"\"\"\n",
        "    # Load audio\n",
        "    audio = processor.load_audio(audio_path)\n",
        "    mel_spec = processor.extract_mel_spectrogram(audio)\n",
        "    \n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
        "    \n",
        "    # Waveform\n",
        "    times = np.arange(len(audio)) / config.SAMPLE_RATE\n",
        "    axes[0].plot(times, audio)\n",
        "    axes[0].set_title(f'Waveform: {os.path.basename(audio_path)}')\n",
        "    axes[0].set_xlabel('Time (s)')\n",
        "    axes[0].set_ylabel('Amplitude')\n",
        "    axes[0].grid(True)\n",
        "    \n",
        "    # Mel Spectrogram\n",
        "    img = librosa.display.specshow(mel_spec, x_axis='time', y_axis='mel',\n",
        "                                   sr=config.SAMPLE_RATE, hop_length=config.HOP_LENGTH,\n",
        "                                   ax=axes[1], cmap='viridis')\n",
        "    axes[1].set_title('Mel Spectrogram')\n",
        "    fig.colorbar(img, ax=axes[1], format='%+2.0f dB')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Play audio\n",
        "    return Audio(audio, rate=config.SAMPLE_RATE)\n",
        "\n",
        "# Example: visualize a sample from each instrument\n",
        "for instrument in config.INSTRUMENTS:\n",
        "    instrument_dir = os.path.join(config.TRAIN_DIR, instrument)\n",
        "    if os.path.exists(instrument_dir):\n",
        "        files = [f for f in os.listdir(instrument_dir) \n",
        "                if f.lower().endswith('.wav')][:1]\n",
        "        if files:\n",
        "            audio_path = os.path.join(instrument_dir, files[0])\n",
        "            print(f\"\\n{instrument.upper()}:\")\n",
        "            display(visualize_audio(audio_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Note Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze note distribution\n",
        "def analyze_note_distribution(data_dir):\n",
        "    note_counts = {note: 0 for note in config.NOTES}\n",
        "    \n",
        "    for instrument in config.INSTRUMENTS:\n",
        "        instrument_dir = os.path.join(data_dir, instrument)\n",
        "        if not os.path.exists(instrument_dir):\n",
        "            continue\n",
        "            \n",
        "        for filename in os.listdir(instrument_dir):\n",
        "            if not filename.lower().endswith(('.wav', '.mp3', '.ogg', '.flac')):\n",
        "                continue\n",
        "            \n",
        "            # Extract note from filename\n",
        "            note = filename.split('_')[0]\n",
        "            if note in note_counts:\n",
        "                note_counts[note] += 1\n",
        "    \n",
        "    return note_counts\n",
        "\n",
        "train_note_dist = analyze_note_distribution(config.TRAIN_DIR)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(20, 6))\n",
        "plt.bar(train_note_dist.keys(), train_note_dist.values())\n",
        "plt.title('Note Distribution in Training Set')\n",
        "plt.xlabel('Note')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nNotes with fewest samples:\")\n",
        "sorted_notes = sorted(train_note_dist.items(), key=lambda x: x[1])\n",
        "for note, count in sorted_notes[:5]:\n",
        "    print(f\"  {note}: {count} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Spectrogram Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare spectrograms of the same note from different instruments\n",
        "def compare_instruments(note='C4'):\n",
        "    \"\"\"Compare spectrograms of the same note from different instruments\"\"\"\n",
        "    fig, axes = plt.subplots(len(config.INSTRUMENTS), 1, figsize=(14, 12))\n",
        "    \n",
        "    for i, instrument in enumerate(config.INSTRUMENTS):\n",
        "        instrument_dir = os.path.join(config.TRAIN_DIR, instrument)\n",
        "        if not os.path.exists(instrument_dir):\n",
        "            continue\n",
        "        \n",
        "        # Find a file with the target note\n",
        "        files = [f for f in os.listdir(instrument_dir) if f.startswith(note)]\n",
        "        if not files:\n",
        "            continue\n",
        "        \n",
        "        audio_path = os.path.join(instrument_dir, files[0])\n",
        "        audio = processor.load_audio(audio_path)\n",
        "        mel_spec = processor.extract_mel_spectrogram(audio)\n",
        "        \n",
        "        # Plot\n",
        "        img = librosa.display.specshow(mel_spec, x_axis='time', y_axis='mel',\n",
        "                                      sr=config.SAMPLE_RATE, hop_length=config.HOP_LENGTH,\n",
        "                                      ax=axes[i], cmap='viridis')\n",
        "        axes[i].set_title(f'{instrument.upper()} - Note {note}')\n",
        "        fig.colorbar(img, ax=axes[i], format='%+2.0f dB')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "compare_instruments('A4')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Data Augmentation Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate data augmentation\n",
        "def show_augmentation_effects(audio_path):\n",
        "    \"\"\"Show effects of different augmentation techniques\"\"\"\n",
        "    # Load original audio\n",
        "    original_audio = processor.load_audio(audio_path)\n",
        "    \n",
        "    # Apply different augmentations\n",
        "    augmentations = {\n",
        "        'Original': original_audio,\n",
        "        'Time Stretch': processor.augment_time_stretch(original_audio, rate=1.1),\n",
        "        'Add Noise': processor.augment_add_noise(original_audio, snr_db=30),\n",
        "        'Volume Change': processor.augment_volume(original_audio, gain_db=10)\n",
        "    }\n",
        "    \n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(len(augmentations), 1, figsize=(14, 12))\n",
        "    \n",
        "    for i, (name, audio) in enumerate(augmentations.items()):\n",
        "        mel_spec = processor.extract_mel_spectrogram(audio)\n",
        "        img = librosa.display.specshow(mel_spec, x_axis='time', y_axis='mel',\n",
        "                                      sr=config.SAMPLE_RATE, hop_length=config.HOP_LENGTH,\n",
        "                                      ax=axes[i], cmap='viridis')\n",
        "        axes[i].set_title(f'{name} - {os.path.basename(audio_path)}')\n",
        "        fig.colorbar(img, ax=axes[i], format='%+2.0f dB')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example\n",
        "for instrument in config.INSTRUMENTS[:1]:  # Just show first instrument\n",
        "    instrument_dir = os.path.join(config.TRAIN_DIR, instrument)\n",
        "    if os.path.exists(instrument_dir):\n",
        "        files = [f for f in os.listdir(instrument_dir) if f.lower().endswith('.wav')][:1]\n",
        "        if files:\n",
        "            show_augmentation_effects(os.path.join(instrument_dir, files[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Load Metadata (if available)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and display metadata\n",
        "metadata_path = os.path.join(config.DATA_DIR, 'train_metadata.csv')\n",
        "if os.path.exists(metadata_path):\n",
        "    df_metadata = pd.read_csv(metadata_path)\n",
        "    print(\"Training Metadata:\")\n",
        "    print(df_metadata.head(10))\n",
        "    print(f\"\\nTotal samples: {len(df_metadata)}\")\n",
        "    \n",
        "    # Group by instrument and note\n",
        "    print(\"\\nSamples per instrument:\")\n",
        "    print(df_metadata.groupby('instrument').size())\n",
        "    \n",
        "    print(\"\\nSamples per note (first 10):\")\n",
        "    print(df_metadata.groupby('note').size().head(10))\n",
        "else:\n",
        "    print(f\"Metadata file not found: {metadata_path}\")\n",
        "    print(\"Run prepare_data.py to create metadata files\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
